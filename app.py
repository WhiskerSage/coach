# AI è¿åŠ¨æ•™ç»ƒ - V1
# ä½ çš„éšèº«è¿åŠ¨æ•™ç»ƒ
#
# å¯åŠ¨æ–¹å¼ï¼š
# å…ˆåˆ‡æ¢ç«¯å£ï¼ˆå¦‚éœ€ä»£ç†ï¼‰ï¼šset HTTPS_PROXY=http://127.0.0.1:7897
# streamlit run app.py æ¥å¯åŠ¨

import streamlit as st
import cv2
import mediapipe as mp
import tempfile
import time
from PIL import Image
import io
import numpy as np
import pandas as pd
import plotly.graph_objs as go
import re
import base64
import json
from datetime import datetime
from langchain_google_genai import ChatGoogleGenerativeAI, HarmCategory, HarmBlockThreshold
from langchain_core.messages import HumanMessage, AIMessage
from langchain_community.document_loaders import TextLoader
import os
import glob
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import MessagesPlaceholder
from langchain.chains.history_aware_retriever import create_history_aware_retriever
from typing import List, Any

# --- é¡µé¢é…ç½®å’Œæ ‡é¢˜ ---
st.set_page_config(
    page_title="AI COACH V1",
    page_icon=None,
    layout="wide"
)

# --- é«˜çº§ UI è®¾è®¡ä¸ CSS æ³¨å…¥ (ä»¿ Bienville Capital æç®€å¥¢åé£æ ¼) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,700;1,400&family=Inter:wght@300;400;600&display=swap');

    /* å…¨å±€èƒŒæ™¯ä¸å­—ä½“ */
    .stApp {
        background-color: #0e0e0e; /* æ›´æ·±é‚ƒçš„é»‘è‰² */
        color: #e0e0e0;
        font-family: 'Inter', sans-serif;
    }

    /* éšè— Streamlit é»˜è®¤å…ƒç´ ï¼Œä½†ä¿ç•™ Header ç”¨äºæ˜¾ç¤ºä¾§è¾¹æ æŒ‰é’® */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* éšè—é¡¶éƒ¨çº¢çº¿ */
    header[data-testid="stHeader"] {
        background: transparent !important;
    }
    
    /* è°ƒæ•´ä¾§è¾¹æ æ”¶ç¼©åçš„æŒ‰é’®ä½ç½®ï¼Œç¡®ä¿å®ƒè´´åˆå·¦ä¸Šè§’ */
    [data-testid="stSidebarCollapsedControl"] {
        position: fixed;
        top: 15px;
        left: 15px;
        width: 40px;
        height: 40px;
    }
    
    /* ä¾§è¾¹æ å¼€å…³æŒ‰é’®é»˜è®¤éšè—ï¼Œé€šè¿‡åŠ¨ç”»å»¶è¿Ÿæ˜¾ç¤º */
    [data-testid="stSidebarCollapsedControl"] {
        color: #ffffff !important;
        background-color: rgba(255, 255, 255, 0.05) !important;
        border-radius: 4px;
        transition: all 0.3s;
        z-index: 1000001 !important;
        opacity: 0;
        animation: fadeInButton 1s ease-in-out forwards;
        animation-delay: 7s; /* å»¶è¿Ÿç›´åˆ°å¼€åœºåŠ¨ç”»ç»“æŸ */
    }
    
    @keyframes fadeInButton {
        to { opacity: 1; }
    }
    
    [data-testid="stSidebarCollapsedControl"]:hover {
        background-color: rgba(255, 255, 255, 0.2) !important;
        color: #ffffff !important;
    }

    /* æ ‡é¢˜æ’ç‰ˆ */
    h1, h2, h3 {
        font-family: 'Playfair Display', serif;
        font-weight: 700;
        letter-spacing: -0.02em;
    }
    
    h1 {
        font-size: 3.5rem !important;
        color: #ffffff;
        margin-bottom: 0.5rem !important;
    }

    /* ä¾§è¾¹æ ç¾åŒ– - æ¢å¤é»˜è®¤å®½åº¦ï¼Œä¿æŒè´¨æ„Ÿ */
    [data-testid="stSidebar"] {
        background-color: #111111;
        border-right: 1px solid #333;
        /* ç§»é™¤å¼ºåˆ¶å®½åº¦è®¾ç½®ï¼Œæ¢å¤ Streamlit é»˜è®¤è¡Œä¸º */
    }

    /* æ ¸å¿ƒä¿®å¤ï¼šç¡®ä¿ä¾§è¾¹æ æ”¶èµ·æ—¶å®Œå…¨éšè—ï¼Œä¸ç•™æ®‹å½± */
    [data-testid="stSidebar"][aria-expanded="false"] {
        display: none !important;
    }

    /* ç¡®ä¿ä¾§è¾¹æ æ”¶èµ·æ—¶ï¼Œä¸»å†…å®¹åŒºåŸŸå æ»¡å…¨å®½ */
    [data-testid="stSidebar"][aria-expanded="false"] ~ .main,
    section[data-testid="stSidebar"][aria-expanded="false"] ~ .main {
        margin-left: 0 !important;
    }
    
    /* ä¾§è¾¹æ å†…çš„ç»„ä»¶é—´è·ä¼˜åŒ– */
    [data-testid="stSidebar"] .block-container {
        padding-top: 3rem;
        padding-left: 2rem;
        padding-right: 2rem;
    }
    
    /* ä¾§è¾¹æ æ ‡é¢˜ */
    [data-testid="stSidebar"] h1 {
        font-family: 'Playfair Display', serif;
        font-size: 2.2rem !important;
        letter-spacing: 1px;
        margin-bottom: 2rem;
        color: #fff;
    }
    
    /* ä¾§è¾¹æ è¾“å…¥æ¡†ä¸æŒ‰é’® */
    [data-testid="stSidebar"] input {
        background-color: #1f1f1f !important;
        border: 1px solid #444 !important;
        padding: 10px !important;
    }
    
    /* File Uploader ç¾åŒ– */
    [data-testid="stFileUploader"] {
        border: 1px dashed #555;
        border-radius: 4px;
        padding: 20px;
        background-color: #161616;
        transition: border-color 0.3s;
    }
    [data-testid="stFileUploader"]:hover {
        border-color: #fff;
    }
    
    /* Expander ç¾åŒ– */
    .streamlit-expanderHeader {
        background-color: #161616 !important;
        color: #ccc !important;
        border: 1px solid #333;
    }
    
    /* è‡ªå®šä¹‰æŒ‰é’®é£æ ¼ - ä¾§è¾¹æ è§¦å‘å™¨ */
    .sidebar-trigger {
        position: fixed;
        top: 20px;
        left: 20px;
        z-index: 9999;
        cursor: pointer;
        color: #fff;
        font-family: 'Inter', sans-serif;
        font-size: 0.9rem;
        letter-spacing: 2px;
        text-transform: uppercase;
        mix-blend-mode: difference;
    }
    
    /* é‡ç‚¹å†…å®¹æ”¾å¤§å¤„ç† */
    .highlight-text {
        font-family: 'Playfair Display', serif;
        font-size: 1.5rem;
        color: #ffffff;
        line-height: 1.6;
        margin: 2rem 0;
        border-left: 3px solid #fff;
        padding-left: 20px;
    }
    
    /* ä¸­æ–‡é€‚é…ä¼˜åŒ– */
    .cn-text {
        font-family: "PingFang SC", "Microsoft YaHei", sans-serif;
    }

    /* æŒ‰é’®ç¾åŒ– - æç®€é»‘ç™½ */
    .stButton > button {
        background-color: #ffffff !important;
        color: #000000 !important;
        border: none !important;
        border-radius: 0px !important; /* é”åˆ©ç›´è§’ */
        font-family: 'Inter', sans-serif !important;
        font-weight: 600 !important;
        text-transform: uppercase;
        letter-spacing: 1px;
        padding: 0.6rem 2rem !important;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        background-color: #cccccc !important;
        transform: translateY(-2px);
    }

    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput > div > div > input {
        background-color: #1a1a1a;
        color: #fff;
        border: 1px solid #333;
        border-radius: 0px;
    }
    .stTextInput > div > div > input:focus {
        border-color: #fff;
    }

    /* ä¼˜åŒ–ä¸»å†…å®¹åŒºåŸŸå¸ƒå±€ - å®Œç¾å±…ä¸­ä¸”å®½å± */
    .stApp {
        display: flex;
        flex-direction: row;
    }

    .main {
        flex: 1;
        margin-left: 0 !important;
        padding-left: 0 !important;
        width: 100% !important;
        display: flex;
        justify-content: center;
    }

    .main .block-container {
        max-width: 90rem !important;
        padding-left: 2rem !important;
        padding-right: 2rem !important;
        padding-top: 2rem !important;
        margin: 0 auto !important;
        width: 100% !important;
    }

    /* è§†é¢‘å®¹å™¨å±…ä¸­ */
    video {
        width: 100% !important;
        display: block;
        margin: 0 auto;
    }

    /* ä¿®å¤ Streamlit å¯èƒ½çš„å†…éƒ¨å…ƒç´ é™åˆ¶ */
    .stApp > header {
        background-color: transparent !important;
    }

    /* è‡ªå®šä¹‰ Landing Page å®¹å™¨ */
    .landing-container {
        padding: 4rem 2rem;
        text-align: left;
        width: 100%; /* ç¡®ä¿å®¹å™¨å æ»¡å¯ç”¨å®½åº¦ */
        max-width: 1000px; /* é™åˆ¶å†…å®¹æœ€å¤§å®½åº¦ */
        margin: 0 auto; /* å…³é”®ï¼šåœ¨å…¨å®½çˆ¶å®¹å™¨ä¸­å±…ä¸­ */
        display: flex;
        flex-direction: column;
        justify-content: center;
        min-height: 85vh;
    }
    
    .landing-hero-text {
        font-family: 'Playfair Display', serif;
        font-size: 5rem; /* å­—ä½“åŠ å¤§ */
        line-height: 1.1;
        font-weight: 700;
        color: #ffffff;
        margin-bottom: 2rem;
        max-width: 100%; /* å…è®¸æ–‡å­—æ¨ªå‘é“ºæ»¡ */
    }
    
    .landing-sub-text {
        font-family: 'Inter', sans-serif;
        font-size: 1.4rem;
        line-height: 1.6;
        color: #a0a0a0;
        margin-bottom: 3rem;
        max-width: 800px; /* å‰¯æ ‡é¢˜å¯ä»¥ç¨çª„ï¼Œä¿æŒé˜…è¯»èˆ’é€‚åº¦ */
        border-left: 2px solid #fff;
        padding-left: 1.5rem;
    }
    
    .feature-list {
        display: flex;
        gap: 4rem; /* å¢åŠ é—´è· */
        flex-wrap: wrap;
        margin-top: 3rem;
        justify-content: flex-start; /* é å·¦å¯¹é½æˆ–å‡åŒ€åˆ†å¸ƒ */
    }
    .feature-item {
        flex: 1;
        min-width: 200px;
    }
    .feature-title {
        font-family: 'Inter', sans-serif;
        font-weight: 600;
        font-size: 0.9rem;
        text-transform: uppercase;
        letter-spacing: 2px;
        color: #666;
        margin-bottom: 0.5rem;
    }
    .feature-desc {
        font-size: 1.1rem;
        color: #ddd;
    }
    
    /* æ¨¡æ‹ŸåŠ è½½åŠ¨ç”»å®¹å™¨ - å…¨å± Overlay */
    .loader-overlay {
        position: fixed;
        top: 0;
        left: 0;
        width: 100vw;
        height: 100vh;
        background-color: #000000;
        z-index: 999999; /* ç¡®ä¿è¦†ç›–æ‰€æœ‰ Streamlit å…ƒç´  */
        display: flex;
        justify-content: center;
        align-items: center;
        flex-direction: column;
        text-align: center;
    }
    .loader-text {
        font-family: 'Playfair Display', serif;
        font-size: 2.5rem;
        color: #fff;
        animation: fadeIn 1.5s ease-in-out;
    }
    @keyframes fadeIn {
        0% { opacity: 0; transform: translateY(10px); }
        100% { opacity: 1; transform: translateY(0); }
    }

</style>
""", unsafe_allow_html=True)


# --- Intro Animation Logic ---
if "intro_shown" not in st.session_state:
    st.session_state.intro_shown = False

def show_intro_animation():
    placeholder = st.empty()
    
    # Sequence 1
    html_1 = """
<div class="loader-overlay">
<div class="loader-text">YOUR BODY DOESN'T NEED MORE EXERCISE.</div>
</div>
"""
    placeholder.markdown(html_1, unsafe_allow_html=True)
    time.sleep(2.5)
    
    # Sequence 2
    html_2 = """
<div class="loader-overlay">
<div class="loader-text" style="color: #a0a0a0;">IT NEEDS <span style="color: #fff; font-style: italic;">SMARTER MOVEMENT.</span></div>
</div>
"""
    placeholder.markdown(html_2, unsafe_allow_html=True)
    time.sleep(2.5)
    
    # Sequence 3
    html_3 = """
<div class="loader-overlay">
<div class="loader-text" style="font-size: 5rem; letter-spacing: 5px;">AI COACH</div>
</div>
"""
    placeholder.markdown(html_3, unsafe_allow_html=True)
    time.sleep(2.0)
    
    placeholder.empty()
    st.session_state.intro_shown = True

# Run intro only once
if not st.session_state.intro_shown:
    show_intro_animation()
    st.rerun() # Rerun to load the main UI cleanly

# --- Main App Logic Starts Here ---
# st.title("ğŸƒâ€â™‚ï¸ AI è¿åŠ¨æ•™ç»ƒ V1") # ç§»é™¤é»˜è®¤æ ‡é¢˜ï¼Œä½¿ç”¨è‡ªå®šä¹‰Landing Page
# st.caption("ä½ çš„éšèº«è¿åŠ¨æ•™ç»ƒï¼Œä¸“ä¸šå§¿æ€åˆ†æä¸æ”¹è¿›å»ºè®®") # ç§»é™¤é»˜è®¤caption



# --- Gemini API é…ç½® (è‡ªåŠ¨ä» secrets è¯»å–) ---
api_key = st.secrets.get('GEMINI_API_KEY', None)
if not api_key:
    st.error("æœªæ£€æµ‹åˆ° Gemini API å¯†é’¥ï¼Œè¯·åœ¨ .streamlit/secrets.toml ä¸­é…ç½® GEMINI_API_KEYã€‚")
    st.stop()

# --- å®šä¹‰å®‰å…¨è®¾ç½® ---
safety_settings = {
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
}

# --- æ•°æ®åº“åŠŸèƒ½ (JSON) ---
DB_FILE = "database.json"

def load_data():
    """ä»JSONæ–‡ä»¶ä¸­åŠ è½½æ‰€æœ‰ç”¨æˆ·æ•°æ®"""
    try:
        with open(DB_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_data(user: str, report: str, df: pd.DataFrame):
    """ä¿å­˜ä¸€æ¬¡åˆ†æä¼šè¯åˆ°JSONæ–‡ä»¶"""
    try:
        all_data = load_data()
        if user not in all_data:
            all_data[user] = []

        # --- æ ¸å¿ƒä¿®å¤ï¼šç¡®ä¿æ•°æ®ç±»å‹æ˜¯JSONå¯åºåˆ—åŒ–çš„ ---
        # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹çš„ session_state df
        df_copy = df.copy()
        # éå†æ‰€æœ‰åˆ—ï¼Œå¦‚æœæ•°æ®æ˜¯æµ®ç‚¹æ•°ç±»å‹ï¼Œåˆ™è½¬æ¢ä¸ºPythonå†…ç½®çš„float
        for col in df_copy.columns:
            if pd.api.types.is_float_dtype(df_copy[col]):
                df_copy[col] = df_copy[col].astype(float)
        
        session_data = {
            "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "report": report,
            "dataframe_json": df_copy.to_json(orient='split')
        }
        all_data[user].append(session_data)

        with open(DB_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=4)
        
        print(f"æˆåŠŸä¿å­˜æ•°æ®åˆ° {DB_FILE}ï¼Œç”¨æˆ·: {user}")
    except Exception as e:
        print(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")
        raise e

# --- é‡‘ç‰ŒåŠŸèƒ½ï¼šå®šä¹‰æ•°æ®åˆ†æå·¥å…· ---
@tool
def get_angle_extremes(joint: str) -> dict:
    """
    è·å–æŒ‡å®šå…³èŠ‚åœ¨è¿åŠ¨è¿‡ç¨‹ä¸­çš„æœ€å¤§å’Œæœ€å°è§’åº¦ã€‚
    å½“ç”¨æˆ·è¯¢é—®å…³äºæŸä¸ªå…³èŠ‚çš„"æ´»åŠ¨èŒƒå›´"ã€"æœ€å¤§å¼¯æ›²è§’åº¦"æˆ–"æœ€å°è§’åº¦"æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚
    å‚æ•° `joint` çš„å¯é€‰å€¼ä¸º 'è†' æˆ– 'é«‹'ã€‚
    """
    if 'analysis_df' not in st.session_state or st.session_state.analysis_df.empty:
        return {"error": "æ— å¯ç”¨åˆ†ææ•°æ®ã€‚è¯·å…ˆä¸Šä¼ å¹¶åˆ†æä¸€ä¸ªè§†é¢‘ã€‚"}
    df = st.session_state.analysis_df
    try:
        left_col, right_col = f'å·¦{joint}è§’åº¦', f'å³{joint}è§’åº¦'
        min_angle = df[[left_col, right_col]].min().min()
        max_angle = df[[left_col, right_col]].max().max()
        return {"å…³èŠ‚": joint, "æœ€å°è§’åº¦": f"{min_angle:.2f}Â°", "æœ€å¤§è§’åº¦": f"{max_angle:.2f}Â°"}
    except KeyError:
        return {"error": f"æ•°æ®æ ¼å¼é”™è¯¯ï¼Œæ‰¾ä¸åˆ°'{joint}'å…³èŠ‚çš„è§’åº¦æ•°æ®ã€‚"}

@tool
def get_max_angle_difference(joint: str) -> dict:
    """
    è®¡ç®—åœ¨æ•´ä¸ªè¿åŠ¨è¿‡ç¨‹ä¸­ï¼Œå·¦å³åŒåå…³èŠ‚ï¼ˆå¦‚å·¦è†å’Œå³è†ï¼‰åœ¨ä»»æ„ä¸€å¸§çš„æœ€å¤§è§’åº¦å·®ã€‚
    å½“ç”¨æˆ·è¯¢é—®å…³äºèº«ä½“"å¯¹ç§°æ€§"ã€"å·¦å³å·®å¼‚"æˆ–"ä¸¤è¾¹ä¸ä¸€è‡´"ç­‰é—®é¢˜æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·ã€‚
    å‚æ•° `joint` çš„å¯é€‰å€¼ä¸º 'è†' æˆ– 'é«‹'ã€‚
    """
    if 'analysis_df' not in st.session_state or st.session_state.analysis_df.empty:
        return {"error": "æ— å¯ç”¨åˆ†ææ•°æ®ã€‚è¯·å…ˆä¸Šä¼ å¹¶åˆ†æä¸€ä¸ªè§†é¢‘ã€‚"}
    df = st.session_state.analysis_df
    try:
        left_col, right_col = f'å·¦{joint}è§’åº¦', f'å³{joint}è§’åº¦'
        df['diff'] = (df[left_col] - df[right_col]).abs()
        max_diff = df['diff'].max()
        return {"å…³èŠ‚": joint, "æœ€å¤§è§’åº¦å·®": f"{max_diff:.2f}Â°"}
    except KeyError:
        return {"error": f"æ•°æ®æ ¼å¼é”™è¯¯ï¼Œæ‰¾ä¸åˆ°'{joint}'å…³èŠ‚çš„è§’åº¦æ•°æ®ã€‚"}


# --- RAG Setup: åˆ›å»ºå¹¶ç¼“å­˜Retriever ---
@st.cache_resource
def get_retriever(api_key):
    """
    åˆ›å»ºçŸ¥è¯†åº“æ£€ç´¢å™¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰
    å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œä¸å½±å“ä¸»è¦çš„è§†é¢‘åˆ†æåŠŸèƒ½
    """
    try:
        # æ‰‹åŠ¨åŠ è½½ knowledge_base ç›®å½•ä¸‹çš„æ‰€æœ‰ .md æ–‡ä»¶
        kb_path = './knowledge_base/'
        md_files = glob.glob(os.path.join(kb_path, '**/*.md'), recursive=True)

        if not md_files:
            print("çŸ¥è¯†åº“ä¸ºç©ºï¼ŒRAGåŠŸèƒ½å°†ä¸ä¼šç”Ÿæ•ˆã€‚")
            return None

        documents = []
        for file_path in md_files:
            try:
                # ä½¿ç”¨ TextLoader åŠ è½½æ¯ä¸ªæ–‡ä»¶ï¼ŒæŒ‡å®šç¼–ç ä¸º utf-8
                loader = TextLoader(file_path, encoding='utf-8')
                documents.extend(loader.load())
            except Exception as e:
                print(f"åŠ è½½æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue

        if not documents:
            print("æ— æ³•åŠ è½½çŸ¥è¯†åº“æ–‡ä»¶ï¼ŒRAGåŠŸèƒ½å°†ä¸ä¼šç”Ÿæ•ˆã€‚")
            return None

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        texts = text_splitter.split_documents(documents)

        print(f"æ­£åœ¨åˆ›å»ºçŸ¥è¯†åº“å‘é‡ç´¢å¼•ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
        embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004", google_api_key=api_key)
        # ä½¿ç”¨FAISSåˆ›å»ºå‘é‡å­˜å‚¨
        vectorstore = FAISS.from_documents(texts, embeddings)
        print(f"âœ“ æˆåŠŸåŠ è½½ {len(md_files)} ä¸ªçŸ¥è¯†åº“æ–‡ä»¶ï¼Œå…± {len(texts)} ä¸ªæ–‡æœ¬å—")
        return vectorstore.as_retriever()
    except Exception as e:
        # é…é¢è¶…é™æˆ–å…¶ä»–é”™è¯¯æ—¶ï¼Œåªæ‰“å°è­¦å‘Šï¼Œä¸ä¸­æ–­åº”ç”¨
        error_msg = str(e)
        if "quota" in error_msg.lower() or "429" in error_msg:
            print(f"âš  RAGåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨: APIé…é¢å·²è¾¾ä¸Šé™")
            print(f"  æç¤º: RAGåŠŸèƒ½éœ€è¦ embedding API é…é¢ï¼Œä¸»è¦çš„è§†é¢‘åˆ†æåŠŸèƒ½ä¸å—å½±å“")
        else:
            print(f"âš  RAGåŠŸèƒ½åˆå§‹åŒ–å¤±è´¥: {error_msg}")
        return None

# --- LangChain åˆå§‹åŒ– ---
try:
    if "llm" not in st.session_state:
        st.session_state.llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash-lite", 
            google_api_key=api_key,
            safety_settings=safety_settings,
        )
    if "history" not in st.session_state:
        st.session_state.history = []  # LangChainçš„æ¶ˆæ¯å†å²
    if "analysis_df" not in st.session_state:
        st.session_state.analysis_df = pd.DataFrame() # ç”¨äºå­˜å‚¨åˆ†ææ•°æ®
    if "retriever" not in st.session_state:
        # åˆå§‹åŒ–RAGï¼ˆå¯é€‰åŠŸèƒ½ï¼Œå¤±è´¥ä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼‰
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“..."):
            st.session_state.retriever = get_retriever(api_key)
            if st.session_state.retriever is None:
                st.info("ğŸ’¡ æç¤ºï¼šçŸ¥è¯†åº“åŠŸèƒ½å½“å‰ä¸å¯ç”¨ï¼ˆå¯èƒ½æ˜¯APIé…é¢é™åˆ¶ï¼‰ï¼Œä½†ä¸å½±å“è§†é¢‘åˆ†æåŠŸèƒ½ã€‚")
    if "agent_executor" not in st.session_state:
        # --- å°†RAGåŒ…è£…æˆä¸€ä¸ªå·¥å…· ---
        retriever_tool = None
        if st.session_state.retriever:
            # åˆ›å»ºä¸€ä¸ªå¯ä»¥å¤„ç†å†å²å¯¹è¯çš„æ£€ç´¢å™¨
            contextualize_q_system_prompt = """
            Given a chat history and the latest user question 
            which might reference context in the chat history, 
            formulate a standalone question which can be understood 
            without the chat history. Do NOT answer the question, 
            just reformulate it if needed and otherwise return it as is.
            """
            contextualize_q_prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", contextualize_q_system_prompt),
                    MessagesPlaceholder("chat_history"),
                    ("human", "{input}"),
                ]
            )
            history_aware_retriever = create_history_aware_retriever(
                st.session_state.llm, st.session_state.retriever, contextualize_q_prompt
            )
            # åˆ›å»ºæ–‡æ¡£é“¾
            qa_system_prompt = """
            You are a professional AI sports coach. Please answer the user's questions strictly based on the "Knowledge Base Context" provided below.
            If the context does not contain enough information to answer the question, politely inform the user "Based on my current knowledge, I cannot answer this question yet," and do not attempt to fabricate an answer.
            All your answers must be in English.
            
            Knowledge Base Context:
            {context}
            """
            qa_prompt = ChatPromptTemplate.from_messages(
                [
                    ("system", qa_system_prompt),
                    MessagesPlaceholder("chat_history"),
                    ("human", "{input}"),
                ]
            )
            question_answer_chain = create_stuff_documents_chain(st.session_state.llm, qa_prompt)
            rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
            
            # å®šä¹‰å·¥å…·
            @tool
            def knowledge_base_retriever(input: str, chat_history: List[Any]) -> str:
                """
                Use this tool when the user asks general questions about sports, fitness, nutrition, recovery, etc.
                Do not use it to answer questions about specific video analysis results.
                """
                response = rag_chain.invoke({"input": input, "chat_history": chat_history})
                return response['answer']
            retriever_tool = knowledge_base_retriever
        
        # --- åˆ›å»ºAgent ---
        tools = [get_angle_extremes, get_max_angle_difference]
        # æš‚æ—¶æ³¨é‡Šæ‰RAGå·¥å…·ä»¥é¿å…å‚æ•°é—®é¢˜
        # if retriever_tool:
        #     tools.append(retriever_tool)

        agent_prompt = ChatPromptTemplate.from_messages([
            ("system", "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIè¿åŠ¨æ•™ç»ƒã€‚ä½ å¯ä»¥è°ƒç”¨å·¥å…·æ¥æŸ¥è¯¢çŸ¥è¯†åº“æˆ–åˆ†ææ•°æ®ã€‚ä½ çš„æ‰€æœ‰å›ç­”éƒ½å¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡ã€‚"),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        agent = create_tool_calling_agent(st.session_state.llm, tools, agent_prompt)
        st.session_state.agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

except Exception as e:
    st.error(f"æ¨¡å‹æˆ–Agentåˆå§‹åŒ–å¤±è´¥: {e}")
    st.stop()


# --- ä¾§è¾¹æ  UI ---
with st.sidebar:
    st.header("æ§åˆ¶é¢æ¿") 
    
    # --- ç”¨æˆ·ç³»ç»Ÿ ---
    username = st.text_input("ç”¨æˆ·åç§°", placeholder="è¾“å…¥æ‚¨çš„åå­—ç”¨äºå­˜æ¡£")
    
    with st.expander("è®­ç»ƒç›®æ ‡ (å¯é€‰)"):
        user_goal = st.text_input("æˆ‘çš„ç›®æ ‡:", placeholder="ä¾‹å¦‚ï¼šæ”¹å–„æ·±è¹²æ—¶çš„è†ç›–å†…æ‰£")

    st.divider()

    st.subheader("ä¸Šä¼ ä¸åˆ†æ")
    # --- ä¼˜åŒ–ç‚¹ï¼šå¢åŠ ç”¨æˆ·å¼•å¯¼ ---
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ è§†é¢‘",
        help="å»ºè®®ï¼šä¸Šä¼  5-15 ç§’çš„çŸ­è§†é¢‘ä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚"
    )

    # --- æ ¸å¿ƒä¿®å¤ï¼šæ‰‹åŠ¨è¿›è¡Œæ–‡ä»¶ç±»å‹éªŒè¯ä»¥ç»•è¿‡Streamlitçš„bug ---
    is_valid_file = False
    if uploaded_file is not None:
        # è·å–æ–‡ä»¶å
        file_name = uploaded_file.name
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        allowed_extensions = ['.mp4', '.mov', '.avi']
        if any(file_name.lower().endswith(ext) for ext in allowed_extensions):
            is_valid_file = True
        else:
            st.error(f"æ ¼å¼æ— æ•ˆã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(allowed_extensions)}")
    
    desired_frames = st.number_input(
        "åˆ†æå¸§æ•°",
        min_value=2, max_value=30, value=6, step=1,
        help="æå–çš„å…³é”®å¸§æ•°é‡ã€‚å»ºè®® 5-20 å¸§ã€‚"
    )
    
    analyze_button = st.button(
        "å¼€å§‹åˆ†æ", 
        use_container_width=True, 
        disabled=not (uploaded_file and username and is_valid_file)
    )
    if not username:
        st.warning("è¯·è¾“å…¥æ‚¨çš„åå­—ä»¥å¯ç”¨åˆ†æã€‚")


# --- è¾…åŠ©å‡½æ•°ï¼šåŠ è½½è§†é¢‘ ---
@st.cache_resource
def get_video_base64(video_path):
    try:
        with open(video_path, "rb") as f:
            data = f.read()
        return base64.b64encode(data).decode()
    except FileNotFoundError:
        return None

# --- ä¸»èŠå¤©ç•Œé¢ ---


# --- ä¼˜åŒ–ç‚¹ï¼šå¢åŠ æ¬¢è¿é¡µ/å¼•å¯¼åŒºï¼Œé¿å…å†·å¯åŠ¨ ---
if not st.session_state.history:
    # åŠ è½½å®£ä¼ è§†é¢‘
    video_path = "/Users/boannn/codes/coach/å®£ä¼ ç‰‡.mp4"
    video_b64 = get_video_base64(video_path)
    video_html = ""
    if video_b64:
        video_html = f"""
<div style="margin: 3rem 0; border-radius: 0px; overflow: hidden; border: 1px solid #333;">
<video autoplay loop muted playsinline width="100%" style="display: block; opacity: 0.8;">
<source src="data:video/mp4;base64,{video_b64}" type="video/mp4">
</video>
</div>
"""

    html_content = f"""
<div class="landing-container">
<div class="landing-hero-text">
YOUR BODY DOESN'T NEED MORE EXERCISE.<br>
IT NEEDS <span style="font-style: italic; color: #888;">SMARTER MOVEMENT.</span>
</div>
<div class="highlight-text cn-text">
æˆ‘ä»¬ä¸ä»…ä»…æ˜¯è®°å½•è¿åŠ¨ï¼Œæ›´æ˜¯åœ¨è§£ç äººä½“åŠ›å­¦ã€‚<br>
ç»“åˆè®¡ç®—æœºè§†è§‰ä¸ç”Ÿæˆå¼ AIï¼Œä¸ºæ‚¨æä¾›å¯é‡åŒ–çš„ä¸“ä¸šæ´å¯Ÿã€‚
</div>
{video_html}
<div class="landing-divider"></div>
<div class="feature-list">
<div class="feature-item">
<div class="feature-title">01. CAPTURE (æ‹æ‘„)</div>
<div class="feature-desc cn-text">ä¸Šä¼ æ‚¨çš„è¿åŠ¨è§†é¢‘ï¼Œæ”¯æŒä»»æ„è§’åº¦ä¸åŠ¨ä½œã€‚</div>
</div>
<div class="feature-item">
<div class="feature-title">02. ANALYZE (åˆ†æ)</div>
<div class="feature-desc cn-text">ç²¾å‡†çš„éª¨éª¼è¿½è¸ªä¸å…³èŠ‚è§’åº¦é‡åŒ–ã€‚</div>
</div>
<div class="feature-item">
<div class="feature-title">03. EVOLVE (è¿›åŒ–)</div>
<div class="feature-desc cn-text">è·å– AI æä¾›çš„ä¸“ä¸šæ”¹è¿›å»ºè®®ä¸è®­ç»ƒè®¡åˆ’ã€‚</div>
</div>
</div>
<div style="margin-top: 4rem; color: #666; font-size: 0.8rem; letter-spacing: 1px;" class="cn-text">
è¯·ç‚¹å‡»å·¦ä¸Šè§’ç®­å¤´å±•å¼€ä¾§è¾¹æ å¼€å§‹ä½“éªŒ &rarr;
</div>
</div>
"""
    st.markdown(html_content, unsafe_allow_html=True)


# æ˜¾ç¤ºå†å²å¯¹è¯è®°å½•
for message in st.session_state.history:
    # ä¸æ˜¾ç¤ºåˆå§‹çš„å¤šæ¨¡æ€ç”¨æˆ·æ¶ˆæ¯ï¼Œåªæ˜¾ç¤ºAIå›å¤å’Œåç»­æ–‡æœ¬å¯¹è¯
    if isinstance(message, AIMessage):
        with st.chat_message("assistant"):
            st.markdown(message.content, unsafe_allow_html=True)
    elif isinstance(message, HumanMessage) and isinstance(message.content, str):
         with st.chat_message("user"):
            st.markdown(message.content, unsafe_allow_html=True)

# --- é‡‘ç‰ŒåŠŸèƒ½ï¼šæ–°å¢è§’åº¦è®¡ç®—å‡½æ•° ---
def calculate_angle(a, b, c):
    """è®¡ç®—ç”±ä¸‰ç‚¹a, b, cæ„æˆçš„è§’åº¦ï¼ˆbä¸ºé¡¶ç‚¹ï¼‰ï¼Œè¿”å›0-180ä¹‹é—´çš„è§’åº¦å€¼"""
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    if angle > 180.0:
        angle = 360 - angle
    return angle

# --- æ ¸å¿ƒå¤„ç†é€»è¾‘ ---
if analyze_button:
    # --- é‡‘ç‰ŒåŠŸèƒ½ï¼šåˆå§‹åŒ–ç”¨äºå­˜å‚¨é‡åŒ–æ•°æ®çš„å­—å…¸ ---
    quantitative_data = {
        "å¸§å·": [],
        "å·¦è†è§’åº¦": [],
        "å³è†è§’åº¦": [],
        "å·¦é«‹è§’åº¦": [],
        "å³é«‹è§’åº¦": []
    }
    with st.spinner("å¤„ç†ä¸­..."):
        st.info("AI æ­£åœ¨åˆ†æ...")
        # --- è§†é¢‘å¤„ç†é€»è¾‘ ---
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
            tfile.write(uploaded_file.read())
            video_path = tfile.name
        
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        if total_frames == 0:
            st.error("æ— æ³•è¯»å–è§†é¢‘ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸåã€‚")
            st.stop()
        
        frame_interval = max(total_frames // desired_frames, 1)
        st.write(f"è§†é¢‘æ€»å¸§æ•°: {total_frames}ã€‚æ­£åœ¨æå– {desired_frames} ä¸ªå…³é”®å¸§ã€‚")
        
        sampled_frames_pil = []
        frame_indices_to_extract = [i * frame_interval for i in range(desired_frames)]
        
        with mp.solutions.pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:
            for frame_index in frame_indices_to_extract:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
                ret, frame = cap.read()
                if not ret:
                    continue
                
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb_frame)
                annotated_image = frame.copy()
                
                if results.pose_landmarks:
                    mp.solutions.drawing_utils.draw_landmarks(
                        annotated_image, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS,
                        landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),
                        connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)
                    )
                
                # --- é‡‘ç‰ŒåŠŸèƒ½ï¼šè®¡ç®—è§’åº¦å¹¶å­˜å‚¨ ---
                try:
                    landmarks = results.pose_landmarks.landmark
                    left_hip = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp.solutions.pose.PoseLandmark.LEFT_HIP.value].y]
                    left_knee = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp.solutions.pose.PoseLandmark.LEFT_KNEE.value].y]
                    left_ankle = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp.solutions.pose.PoseLandmark.LEFT_ANKLE.value].y]
                    left_shoulder = [landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp.solutions.pose.PoseLandmark.LEFT_SHOULDER.value].y]
                    right_hip = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp.solutions.pose.PoseLandmark.RIGHT_HIP.value].y]
                    right_knee = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp.solutions.pose.PoseLandmark.RIGHT_KNEE.value].y]
                    right_ankle = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp.solutions.pose.PoseLandmark.RIGHT_ANKLE.value].y]
                    right_shoulder = [landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp.solutions.pose.PoseLandmark.RIGHT_SHOULDER.value].y]
                    lk_angle = calculate_angle(left_hip, left_knee, left_ankle)
                    rk_angle = calculate_angle(right_hip, right_knee, right_ankle)
                    lh_angle = calculate_angle(left_shoulder, left_hip, left_knee)
                    rh_angle = calculate_angle(right_shoulder, right_hip, right_knee)
                    quantitative_data["å¸§å·"].append(frame_index)
                    quantitative_data["å·¦è†è§’åº¦"].append(lk_angle)
                    quantitative_data["å³è†è§’åº¦"].append(rk_angle)
                    quantitative_data["å·¦é«‹è§’åº¦"].append(lh_angle)
                    quantitative_data["å³é«‹è§’åº¦"].append(rh_angle)
                except Exception as e:
                    print(f"åœ¨å¸§ {frame_index} è®¡ç®—è§’åº¦æ—¶å‡ºé”™: {e}")
                    pass
                
                pil_image = Image.fromarray(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))
                sampled_frames_pil.append(pil_image)
        
        cap.release()
        st.write(f"æå–å®Œæˆã€‚å…±æ•è· {len(sampled_frames_pil)} å¸§ã€‚")

        if not sampled_frames_pil:
            st.error("æœªæå–åˆ°æœ‰æ•ˆå¸§ã€‚")
        else:
            st.session_state.analysis_df = pd.DataFrame(quantitative_data)
            df = st.session_state.analysis_df
            # --- åä¸½å…³é”®å¸§æ¨ªå‘å¤§å›¾å±•ç¤º ---
            st.markdown("#### å…³é”®å¸§é¢„è§ˆ")
            cols = st.columns(len(sampled_frames_pil))
            for i, img in enumerate(sampled_frames_pil):
                with cols[i]:
                    st.image(img, caption=f"ç¬¬ {i+1} å¸§", use_container_width=True)

            # --- LangChain Prompt & Invocation ---
            focus_prompt = f"ç”¨æˆ·çš„è®­ç»ƒç›®æ ‡æ˜¯{user_goal}ã€‚å¦‚æœ‰ç›¸å…³é—®é¢˜è¯·é€‚å½“å…³æ³¨ã€‚" if user_goal else ""
            data_prompt = f"\nä»¥ä¸‹ä¸ºéƒ¨åˆ†å¸§çš„é‡åŒ–æ•°æ®ï¼Œä»…ä¾›ä½ åˆ†ææ—¶å‚è€ƒï¼Œé‡ç‚¹è¯·ç»“åˆè§†é¢‘å¸§çš„å¤šæ¨¡æ€ç†è§£è¿›è¡Œç»¼åˆåˆ¤æ–­ï¼š\n{df.to_markdown(index=False)}\n" if not df.empty else ""
            prompt_text = f"""
            You are a top-tier sports biomechanics expert and AI coach. All your responses must be in Simplified Chinese.
            Your task is to provide a professional, in-depth analysis report based primarily on the user-uploaded video frames, with some quantitative data (for reference only) and a focus on multi-modal understanding.
            {focus_prompt}
            {data_prompt}

            **Output Format Requirements:**
            Please strictly organize your response into the following three sections:

            - **ã€ç»¼åˆè¯„ä¼°ä¸å¾—åˆ†ã€‘**: 
              First, you **must use a Markdown table** to clearly display scores for four dimensions. The table should include "è¯„ä¼°ç»´åº¦" (Assessment Dimension) and "å¾—åˆ† (æ»¡åˆ†10)" (Score out of 10) columns.
              Then, provide a brief overall evaluation below the table.

            - **ã€å¤šæ¨¡æ€è¯Šæ–­ã€‘**: 
              This is the core of the report. Please **focus on the multi-modal understanding of video frames, using quantitative data only as auxiliary support**, and explain the basis for your scoring item by item.
              For example: "åœ¨ç¬¬Xå¸§ä¸­è§‚å¯Ÿåˆ°...". Do not just discuss quantitative data.

            - **ã€æ ¸å¿ƒæ”¹è¿›å»ºè®®ã€‘**: 
              Provide the most critical and actionable training suggestions targeting the lower-scoring dimensions and the user's goals.

            Your tone should be professional, rigorous, and encouraging. Please begin your analysis.
            """
            
            # å°†PILå›¾åƒè½¬æ¢ä¸ºLangChainæ‰€éœ€æ ¼å¼
            image_messages = []
            for img in sampled_frames_pil:
                img.thumbnail((768, 768))
                buf = io.BytesIO()
                img.save(buf, format='JPEG')
                base64_image = base64.b64encode(buf.getvalue()).decode('utf-8')
                image_messages.append({
                    "type": "image_url",
                    "image_url": f"data:image/jpeg;base64,{base64_image}"
                })

            # åˆ›å»ºLangChainçš„å¤šæ¨¡æ€æ¶ˆæ¯
            user_message = HumanMessage(
                content=[{"type": "text", "text": prompt_text}] + image_messages
            )
            
            # æ¸…ç©ºå†å²ï¼Œå¼€å§‹æ–°çš„åˆ†æä¼šè¯
            st.session_state.history = []

            try:
                st.info("æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
                with st.chat_message("assistant"):
                    response_container = st.empty()
                    collected_messages = ""
                    # ä½¿ç”¨LangChain LLMè¿›è¡Œæµå¼è°ƒç”¨
                    response = st.session_state.llm.stream([user_message])
                    for chunk in response:
                        if chunk.content:
                            collected_messages += chunk.content
                            response_container.markdown(collected_messages, unsafe_allow_html=True)

                    # å°†AIçš„å®Œæ•´å›å¤å­˜å…¥å†å²è®°å½•
                    st.session_state.history.append(AIMessage(content=collected_messages))

                    # --- æ ¸å¿ƒä¿®å¤ï¼šè‡ªåŠ¨å­˜æ¡£åˆ†æç»“æœ ---
                    if collected_messages and username:
                        try:
                            save_data(username, collected_messages, df)
                            st.success(f"å·²ä¸ºç”¨æˆ· {username} å­˜æ¡£åˆ†æç»“æœ")
                        except Exception as e:
                            st.error(f"å­˜æ¡£å¤±è´¥: {e}")
                            print(f"å­˜æ¡£é”™è¯¯è¯¦æƒ…: {e}")

                    # --- åˆ†æå®Œæˆåçš„å›¾è¡¨å’Œä¸‹è½½æŒ‰é’® ---
                    if not df.empty:
                        st.write("---")
                        st.subheader("è¯¦ç»†æ•°æ®æŒ‡æ ‡")
                        
                        # è†å…³èŠ‚è§’åº¦å˜åŒ–
                        fig_knee = go.Figure()
                        fig_knee.add_trace(go.Scatter(
                            x=df['å¸§å·'], 
                            y=df['å·¦è†è§’åº¦'], 
                            mode='lines+markers', 
                            name='å·¦è†', 
                            line=dict(color='red', width=4), 
                            marker=dict(size=10)
                        ))
                        fig_knee.add_trace(go.Scatter(
                            x=df['å¸§å·'], 
                            y=df['å³è†è§’åº¦'], 
                            mode='lines+markers', 
                            name='å³è†', 
                            line=dict(color='blue', width=4), 
                            marker=dict(size=10)
                        ))
                        fig_knee.update_layout(
                            title='è†å…³èŠ‚è§’åº¦', 
                            xaxis_title='å¸§å·', 
                            yaxis_title='è§’åº¦ (Â°)', 
                            template='plotly_dark',
                            height=400
                        )
                        st.plotly_chart(fig_knee, use_container_width=True, key="knee_chart")
                        
                        # é«‹å…³èŠ‚è§’åº¦å˜åŒ–
                        fig_hip = go.Figure()
                        fig_hip.add_trace(go.Scatter(
                            x=df['å¸§å·'], 
                            y=df['å·¦é«‹è§’åº¦'], 
                            mode='lines+markers', 
                            name='å·¦é«‹', 
                            line=dict(color='orange', width=4), 
                            marker=dict(size=10)
                        ))
                        fig_hip.add_trace(go.Scatter(
                            x=df['å¸§å·'], 
                            y=df['å³é«‹è§’åº¦'], 
                            mode='lines+markers', 
                            name='å³é«‹', 
                            line=dict(color='green', width=4), 
                            marker=dict(size=10)
                        ))
                        fig_hip.update_layout(
                            title='é«‹å…³èŠ‚è§’åº¦', 
                            xaxis_title='å¸§å·', 
                            yaxis_title='è§’åº¦ (Â°)', 
                            template='plotly_dark',
                            height=400
                        )
                        st.plotly_chart(fig_hip, use_container_width=True, key="hip_chart")
                        
                        with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®"):
                            st.dataframe(df, use_container_width=True)
                    
                    # åªä¿ç•™ä¸‹è½½åŠŸèƒ½
                    if collected_messages:
                        st.download_button(
                            label="ä¸‹è½½æŠ¥å‘Š",
                            data=collected_messages,
                            file_name=f"ai_coach_report_{username}_{time.strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown",
                            use_container_width=True
                        )
                st.success("åˆ†æå®Œæˆï¼")
            except Exception as e:
                error_str = str(e)
                if "safety" in error_str.lower() or "blocked" in error_str.lower():
                     st.error("è¯·æ±‚è¢«å®‰å…¨è®¾ç½®é˜»æ­¢ã€‚è¯·å°è¯•å…¶ä»–è§†é¢‘ã€‚")
                else:
                     st.error(f"AI é”™è¯¯: {e}")
                print(e)

# ä»…åœ¨AIæœ‰å›å¤åï¼ˆå³åˆ†æå®Œæˆåï¼‰æ˜¾ç¤ºè¾“å…¥æ¡†
if st.session_state.history and isinstance(st.session_state.history[-1], AIMessage):
    if prompt := st.chat_input('å…³äºåˆ†æç»“æœï¼Œæ‚¨æƒ³é—® AI ä»€ä¹ˆ...'):
        user_prompt_message = HumanMessage(content=prompt)
        st.session_state.history.append(user_prompt_message)
        
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            response_container = st.empty()
            collected_messages = ""
            
            # --- Agent é€»è¾‘ ---
            try:
                response_stream = st.session_state.agent_executor.stream({
                    "input": prompt,
                    "chat_history": st.session_state.history
                })
                for chunk in response_stream:
                    if "output" in chunk:
                        collected_messages = chunk['output']
                        response_container.markdown(collected_messages, unsafe_allow_html=True)
            except Exception as e:
                collected_messages = f"è°ƒç”¨Agentæ—¶å‡ºé”™: {e}"
                response_container.markdown(collected_messages)

            # å°†åç»­å›å¤ä¹ŸåŠ å…¥å†å²
            st.session_state.history.append(AIMessage(content=collected_messages))

